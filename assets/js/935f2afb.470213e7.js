"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[53],{1109:function(e){e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"installationSidebar":[{"type":"category","label":"Installation and Usage","items":[{"type":"link","label":"Installation","href":"/docs/installation/","docId":"installation/installation"},{"type":"link","label":"Testing","href":"/docs/installation/testing","docId":"installation/testing"},{"type":"link","label":"Github Repository Synchronization (after cleanup)","href":"/docs/installation/github-squash-sync","docId":"installation/github-squash-sync"}],"collapsible":true,"collapsed":true}],"userguideSidebar":[{"type":"link","label":"CacheLib user guide","href":"/docs/","docId":"cache_library_intro"},{"type":"category","label":"User Guide","collapsed":false,"items":[{"type":"category","label":"Overview","collapsed":true,"items":[{"type":"link","label":"About CacheLib","href":"/docs/Cache_Library_User_Guides/About_CacheLib","docId":"Cache_Library_User_Guides/About_CacheLib"},{"type":"link","label":"Terms","href":"/docs/Cache_Library_User_Guides/terms","docId":"Cache_Library_User_Guides/terms"}],"collapsible":true},{"type":"category","label":"Getting Started with Cache Library","collapsed":true,"items":[{"type":"link","label":"Set up a simple dram cache","href":"/docs/Cache_Library_User_Guides/Set_up_a_simple_cache","docId":"Cache_Library_User_Guides/Set_up_a_simple_cache"},{"type":"link","label":"Write data to cache","href":"/docs/Cache_Library_User_Guides/Write_data_to_cache","docId":"Cache_Library_User_Guides/Write_data_to_cache"},{"type":"link","label":"Read data from cache","href":"/docs/Cache_Library_User_Guides/Read_data_from_cache","docId":"Cache_Library_User_Guides/Read_data_from_cache"},{"type":"link","label":"Remove data from cache","href":"/docs/Cache_Library_User_Guides/Remove_data_from_cache","docId":"Cache_Library_User_Guides/Remove_data_from_cache"},{"type":"link","label":"Visit data in cache","href":"/docs/Cache_Library_User_Guides/Visit_data_in_cache","docId":"Cache_Library_User_Guides/Visit_data_in_cache"},{"type":"link","label":"FAQ","href":"/docs/Cache_Library_User_Guides/faq","docId":"Cache_Library_User_Guides/faq"}],"collapsible":true},{"type":"category","label":"Cache memory management","collapsed":true,"items":[{"type":"link","label":"Item and ItemHandle","href":"/docs/Cache_Library_User_Guides/Item_and_ItemHandle","docId":"Cache_Library_User_Guides/Item_and_ItemHandle"},{"type":"link","label":"Eviction policy","href":"/docs/Cache_Library_User_Guides/eviction_policy","docId":"Cache_Library_User_Guides/eviction_policy"},{"type":"link","label":"Partition cache into pools","href":"/docs/Cache_Library_User_Guides/Partition_cache_into_pools","docId":"Cache_Library_User_Guides/Partition_cache_into_pools"},{"type":"link","label":"Configure lookup performance","href":"/docs/Cache_Library_User_Guides/Configure_HashTable","docId":"Cache_Library_User_Guides/Configure_HashTable"},{"type":"link","label":"Item Destructor","href":"/docs/Cache_Library_User_Guides/Item_Destructor","docId":"Cache_Library_User_Guides/Item_Destructor"},{"type":"link","label":"Remove callback","href":"/docs/Cache_Library_User_Guides/Remove_callback","docId":"Cache_Library_User_Guides/Remove_callback"},{"type":"link","label":"Cache persistence","href":"/docs/Cache_Library_User_Guides/Cache_persistence","docId":"Cache_Library_User_Guides/Cache_persistence"},{"type":"link","label":"Cross Host Cache Persistence","href":"/docs/Cache_Library_User_Guides/Cross_Host_Cache_Persistence","docId":"Cache_Library_User_Guides/Cross_Host_Cache_Persistence"},{"type":"link","label":"TTL Reaper","href":"/docs/Cache_Library_User_Guides/ttl_reaper","docId":"Cache_Library_User_Guides/ttl_reaper"},{"type":"link","label":"Oom protection","href":"/docs/Cache_Library_User_Guides/oom_protection","docId":"Cache_Library_User_Guides/oom_protection"},{"type":"link","label":"Pool rebalance strategy","href":"/docs/Cache_Library_User_Guides/pool_rebalance_strategy","docId":"Cache_Library_User_Guides/pool_rebalance_strategy"},{"type":"link","label":"Automatic pool resizing","href":"/docs/Cache_Library_User_Guides/automatic_pool_resizing","docId":"Cache_Library_User_Guides/automatic_pool_resizing"}],"collapsible":true},{"type":"category","label":"Hybrid Cache","collapsed":true,"items":[{"type":"link","label":"HybridCache","href":"/docs/Cache_Library_User_Guides/HybridCache","docId":"Cache_Library_User_Guides/HybridCache"},{"type":"link","label":"Configure HybridCache","href":"/docs/Cache_Library_User_Guides/Configure_HybridCache","docId":"Cache_Library_User_Guides/Configure_HybridCache"}],"collapsible":true},{"type":"category","label":"Advanced Features","collapsed":true,"items":[{"type":"link","label":"Chained items","href":"/docs/Cache_Library_User_Guides/chained_items","docId":"Cache_Library_User_Guides/chained_items"},{"type":"link","label":"Compact cache","href":"/docs/Cache_Library_User_Guides/compact_cache","docId":"Cache_Library_User_Guides/compact_cache"},{"type":"link","label":"Structured cache","href":"/docs/Cache_Library_User_Guides/Structured_Cache","docId":"Cache_Library_User_Guides/Structured_Cache"}],"collapsible":true},{"type":"category","label":"Reference","collapsed":true,"items":[{"type":"link","label":"Tuning DRAM cache efficiency","href":"/docs/Cache_Library_User_Guides/Tuning_DRAM_cache_efficiency","docId":"Cache_Library_User_Guides/Tuning_DRAM_cache_efficiency"},{"type":"link","label":"CacheLib configs","href":"/docs/Cache_Library_User_Guides/CacheLib_configs","docId":"Cache_Library_User_Guides/CacheLib_configs"}],"collapsible":true}],"collapsible":true}],"cachebenchSideBar":[{"type":"category","label":"Cachebench","collapsed":true,"items":[{"type":"link","label":"Overview","href":"/docs/Cache_Library_User_Guides/Cachebench_Overview","docId":"Cache_Library_User_Guides/Cachebench_Overview"},{"type":"link","label":"Configuring cachebench parameters","href":"/docs/Cache_Library_User_Guides/Configuring_cachebench_parameters","docId":"Cache_Library_User_Guides/Configuring_cachebench_parameters"},{"type":"link","label":"Contributing to Cachebench","href":"/docs/Cache_Library_User_Guides/Developing_for_Cachebench","docId":"Cache_Library_User_Guides/Developing_for_Cachebench"},{"type":"link","label":"Evaluating SSD hardware for Facebook workloads","href":"/docs/Cache_Library_User_Guides/Cachebench_FB_HW_eval","docId":"Cache_Library_User_Guides/Cachebench_FB_HW_eval"}],"collapsible":true}],"archguideSideBar":[{"type":"category","label":"Architecture Guide","collapsed":false,"items":[{"type":"link","label":"CacheLib Architecture Guide","href":"/docs/Cache_Library_Architecture_Guide/doc4","docId":"Cache_Library_Architecture_Guide/doc4"}],"collapsible":true}]},"docs":{"Cache_Library_Architecture_Guide/doc4":{"id":"Cache_Library_Architecture_Guide/doc4","title":"CacheLib Architecture Guide","description":"Will be published soon...","sidebar":"archguideSideBar"},"cache_library_intro":{"id":"cache_library_intro","title":"CacheLib user guide","description":"Cache library (CacheLib) is a C++ library for accessing and managing cache data. It is a","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/About_CacheLib":{"id":"Cache_Library_User_Guides/About_CacheLib","title":"About CacheLib","description":"CacheLib is a C++ library for accessing and managing cache data. It is a thread-safe API that enables developers to build and customize scalable, concurrent caches. It is targeted at applications that dedicate gigabytes of memory to cache information.","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/automatic_pool_resizing":{"id":"Cache_Library_User_Guides/automatic_pool_resizing","title":"Automatic pool resizing","description":"This feature is incomplete and untested in prod. If you\'re interested, reach out to us and we can work out a plan to complete it.","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/Cache_persistence":{"id":"Cache_Library_User_Guides/Cache_persistence","title":"Cache persistence","description":"Cachelib supports persisting the cache across process restarts. This is useful when you want to restart your binary that contains a  cache and not lose the cache upon restart.  Cache persistence only works when you restart your process in the same machine. This does not provide persistence across machines.","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/Cachebench_FB_HW_eval":{"id":"Cache_Library_User_Guides/Cachebench_FB_HW_eval","title":"Evaluating SSD hardware for Facebook workloads","description":"CacheBench is a cache benchmark tool used to stress the storage and","sidebar":"cachebenchSideBar"},"Cache_Library_User_Guides/Cachebench_Overview":{"id":"Cache_Library_User_Guides/Cachebench_Overview","title":"Overview","description":"CacheBench is a benchmark and stress testing  tool to evaluate cache","sidebar":"cachebenchSideBar"},"Cache_Library_User_Guides/CacheLib_configs":{"id":"Cache_Library_User_Guides/CacheLib_configs","title":"CacheLib configs","description":"This document covers the configs that CacheLib cache consumes. In general there are two types of configs: the static ones that are consumed only when CacheAllocator is constructed, the dynamic ones that can be updated without restarting CacheAllocator.","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/chained_items":{"id":"Cache_Library_User_Guides/chained_items","title":"Chained items","description":"The allocate() method allocates memory for data whose size is less than the maximum allocation size (default: 4MB). To cache data whose size exceeds maximum allocation size, use chained allocations.","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/compact_cache":{"id":"Cache_Library_User_Guides/compact_cache","title":"Compact cache","description":"This feature is in maintenance mode. All future development plans are dropped. We understand there is value in optimizing for very small payloads, but we think the correct direction is to reduce item overhead in the regular cache instead of adding small, separate caches that offer low space overhead. Please reach out to us directly if you have a strong need for a RAM cache optimized for very small items.","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/Configure_HashTable":{"id":"Cache_Library_User_Guides/Configure_HashTable","title":"Configure lookup performance","description":"When you use a cache instance, it comes with a hash table that the find() method uses to look up an item in cache by its key. The current implementation uses a chained, open addressable hash table for keeping the lookup performance as small as possible. There are a few knobs to tune that will impact the lookup and insert cost of the cache. For this reason, the default parameters for this are left as the most-unoptimized state. To tune the HashTable, you need configure two important parameters in the AccessConfig type in your cache.","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/Configure_HybridCache":{"id":"Cache_Library_User_Guides/Configure_HybridCache","title":"Configure HybridCache","description":"Enabling hybrid cache","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/Configuring_cachebench_parameters":{"id":"Cache_Library_User_Guides/Configuring_cachebench_parameters","title":"Configuring cachebench parameters","description":"Command line parameters","sidebar":"cachebenchSideBar"},"Cache_Library_User_Guides/Cross_Host_Cache_Persistence":{"id":"Cache_Library_User_Guides/Cross_Host_Cache_Persistence","title":"Cross Host Cache Persistence","description":"Cachelib supports persisting the cache into a remote storage and restoring in a","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/Developing_for_Cachebench":{"id":"Cache_Library_User_Guides/Developing_for_Cachebench","title":"Contributing to Cachebench","description":"CacheBench provides features to model cache workloads, represent cache workloads, to run cache benchmarks and more. This guide will explain how CacheBench is structured and how to add new configs or build features for it.","sidebar":"cachebenchSideBar"},"Cache_Library_User_Guides/doc5":{"id":"Cache_Library_User_Guides/doc5","title":"CacheLib User Guide","description":"Will be published soon..."},"Cache_Library_User_Guides/eviction_policy":{"id":"Cache_Library_User_Guides/eviction_policy","title":"Eviction policy","description":"Cachelib offers different eviction policies, suitable for different use cases. To select a specific eviction policy, choose the appropriate allocator type.","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/faq":{"id":"Cache_Library_User_Guides/faq","title":"FAQ","description":"My cache instance is broken. Help!","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/HybridCache":{"id":"Cache_Library_User_Guides/HybridCache","title":"HybridCache","description":"HybridCache feature enables CacheAllocator to extend the DRAM cache to NVM. With HybridCache, cachelib can seamlessly move Items stored in cache across DRAM and NVM as they are accessed. Using HybridCache, you can shrink your DRAM footprint of the cache and replace it with NVM like Flash. This can also enable you to achieve large cache capacities for the same or relatively lower power and dollar cost.","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/Item_and_ItemHandle":{"id":"Cache_Library_User_Guides/Item_and_ItemHandle","title":"Item and ItemHandle","description":"An item is the fundamental memory allocation backing an object in cache. Throughout this guide, we sometimes use item and allocation interchangeably. We use allocation when we discuss memory allocation or footprint. And we use item when we want to emphasize cached objects. An item is associated with a key and a byte array allocated by the allocate() method. We use the key to look up the item.","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/Item_Destructor":{"id":"Cache_Library_User_Guides/Item_Destructor","title":"Item Destructor","description":"Item Destructor provides destructor semantics for an item in the cache. This","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/oom_protection":{"id":"Cache_Library_User_Guides/oom_protection","title":"Oom protection","description":"Cachelib can dynamically grow or shrink the total cache footprint from its configured size based on the memory pressure in your system. We call this feature MemoryMonitor. When it is enabled, cachelib watches for the memory pressure through system metrics and releases cache memory back to the system. When the memory pressure eases, cachelib can reclaim back the memory and grow to its configured size. MemoryMonitor enables you to size your cache without having to worry about your system\'s running out of memory when regular heap memory grows or system free memory drops. It also enables you to be less relaxed about coming up with an optimal cache size or relaxing the head room you need to maintain in anticipation of sudden memory growth.","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/Partition_cache_into_pools":{"id":"Cache_Library_User_Guides/Partition_cache_into_pools","title":"Partition cache into pools","description":"One easy way to manage your cache\'s memory is to partition it into pools. This is useful when your application has knowledge of different objects and you want to cache them into different pools or you want to set cache memory limits based on application specific context. For example, if you are caching photos on a 20 GB cache, you can separate celebrity photos from cat photos by storing them in two different pools and restrict the size of each pool.","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/pool_rebalance_strategy":{"id":"Cache_Library_User_Guides/pool_rebalance_strategy","title":"Pool rebalance strategy","description":"When do you need pool rebalancing?","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/Read_data_from_cache":{"id":"Cache_Library_User_Guides/Read_data_from_cache","title":"Read data from cache","description":"An item written to cache by cachelib is associated with a key. To read the item from cache, call the find() method (defined in allocator/CacheAllocator.h) with the key to look up the item:","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/Remove_callback":{"id":"Cache_Library_User_Guides/Remove_callback","title":"Remove callback","description":"Use Item Destructor whenever is possible, contact us if it","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/Remove_data_from_cache":{"id":"Cache_Library_User_Guides/Remove_data_from_cache","title":"Remove data from cache","description":"To remove data from cache, call these methods declared in allocator/CacheAllocator.h:","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/Set_up_a_simple_cache":{"id":"Cache_Library_User_Guides/Set_up_a_simple_cache","title":"Set up a simple dram cache","description":"Before calling cachelib to cache your data, set up a simple dram cache first.","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/Structured_Cache":{"id":"Cache_Library_User_Guides/Structured_Cache","title":"Structured cache","description":"Cachelib enables you to build structured data on top of a cache instead of treating it as just a blob-cache. Data structures let you focus on the actual logic instead of being worried about where a memory allocation comes from. Of course, we\'re still bound by physical limits such as the 4 MB ceiling for any single piece of allocations, but in practice we rarely need to make use of that big an allocation. We provide a generic memory allocator that can take in one or more buffers of memory (one buffer correspond to an item type in cache). Cachelib data types are built by making use of this memory allocator.","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/terms":{"id":"Cache_Library_User_Guides/terms","title":"Terms","description":"Item","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/ttl_reaper":{"id":"Cache_Library_User_Guides/ttl_reaper","title":"TTL Reaper","description":"Cachelib allocators support time to live (TTL) on an item natively at the granularity of seconds. When you set a TTL on an item, the item is automatically reaped if it is still present in the cache after its expiry.  The find() method returns an empty handle (nullptr) for an item that has expired.","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/Tuning_DRAM_cache_efficiency":{"id":"Cache_Library_User_Guides/Tuning_DRAM_cache_efficiency","title":"Tuning DRAM cache efficiency","description":"Reduce fragmentation","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/Visit_data_in_cache":{"id":"Cache_Library_User_Guides/Visit_data_in_cache","title":"Visit data in cache","description":"Cachelib provides a concurrent iterator to visit unchained data (items) in a cache while other threads are inserting data to or removing data from the cache. At any time, an item visited by the iterator is guaranteed to be valid even if it is concurrently removed by another thread.","sidebar":"userguideSidebar"},"Cache_Library_User_Guides/Write_data_to_cache":{"id":"Cache_Library_User_Guides/Write_data_to_cache","title":"Write data to cache","description":"After setting up your cache, you can start writing data to it.","sidebar":"userguideSidebar"},"facebook/internal-test":{"id":"facebook/internal-test","title":"An Internal Document Test","description":"This is an internal document, it should not appear on Github."},"installation/github-squash-sync":{"id":"installation/github-squash-sync","title":"Github Repository Synchronization (after cleanup)","description":"In preparation of making CacheLib public, the CacheLib github repository","sidebar":"installationSidebar"},"installation/installation":{"id":"installation/installation","title":"Installation","description":"Dependencies","sidebar":"installationSidebar"},"installation/testing":{"id":"installation/testing","title":"Testing","description":"Cachelib includes many unit tests for various components","sidebar":"installationSidebar"}}}')}}]);